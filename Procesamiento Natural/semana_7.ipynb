{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "from IPython.display import HTML\n",
        "\n",
        "html_code = \"\"\"\n",
        "<div style=\"text-align: center;\n",
        "            background-color: rgba(246, 211, 36, 0.8);\">\n",
        "    <h1 style=\"color: black;\n",
        "               font-size: 180%;\n",
        "               font-family: Nexa;\n",
        "               letter-spacing: 0px;\n",
        "               padding: 10px;\">\n",
        "        Entregable Semana 7\n",
        "    </h1>\n",
        "</div>\n",
        "\n",
        "<h2 style=\"text-align: center;\n",
        "           color: rgba(195, 172, 71, 1);\n",
        "           font-family: Nexa;\n",
        "           font-size: 180%;\n",
        "           letter-spacing: 0px;\">\n",
        "Predicción de texto utilizando redes neuronales\n",
        "</h2>\n",
        "\n",
        "<div style=\"text-align: center;\n",
        "            background-color: white;\">\n",
        "    <h1 style=\"color: black;\n",
        "               font-size: 140%;\n",
        "               font-family: Nexa;\n",
        "               letter-spacing: 0.0px;\n",
        "               padding: 0px;\">\n",
        "        <br><span style=\"font-weight:normal;\">Melissa Fonseca Veitia</span><br>\n",
        "         <br><span style=\"font-weight:normal;\">Darwin Yadir Londoño Ochoa</span><br>\n",
        "         <br><span style=\"font-weight:normal;\">Samir Romero Cárdenas</span><br>\n",
        "         <br><span style=\"font-weight:normal;\">Ruber Alberto Barrios Rodríguez</span><br>\n",
        "\n",
        "        <br>\n",
        "        <span style=\"font-weight:bold;\">Uniminuto</span><br>\n",
        "        <span style=\"font-weight:bold;\">Procesamiento de Lenguaje Natural</span><br>\n",
        "        <br>\n",
        "        <span style=\"font-weight:normal;\">Docente: Claudia Marcela Ospina Mosquera</span><br>\n",
        "        <br>\n",
        "        Febrero - 2024<br>\n",
        "        <br>\n",
        "    </h1>\n",
        "</div>\n",
        "\n",
        "\n",
        "<hr style=\"border: 1px solid rgba(195, 172, 71, 1);\"> <!-- Línea larga -->\n",
        "\"\"\"\n",
        "\n",
        "display(HTML(html_code))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 555
        },
        "cellView": "form",
        "id": "NxqJWq12CGrc",
        "outputId": "6bb63387-2e89-4dc5-f2d7-c9eb03d46da7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<div style=\"text-align: center;\n",
              "            background-color: rgba(246, 211, 36, 0.8);\">\n",
              "    <h1 style=\"color: black;\n",
              "               font-size: 180%;\n",
              "               font-family: Nexa;\n",
              "               letter-spacing: 0px;\n",
              "               padding: 10px;\">\n",
              "        Entregable Semana 7\n",
              "    </h1>\n",
              "</div>\n",
              "\n",
              "<h2 style=\"text-align: center;\n",
              "           color: rgba(195, 172, 71, 1);\n",
              "           font-family: Nexa;\n",
              "           font-size: 180%;\n",
              "           letter-spacing: 0px;\">\n",
              "Predicción de texto utilizando redes neuronales\n",
              "</h2>\n",
              "\n",
              "<div style=\"text-align: center;\n",
              "            background-color: white;\">\n",
              "    <h1 style=\"color: black;\n",
              "               font-size: 140%;\n",
              "               font-family: Nexa;\n",
              "               letter-spacing: 0.0px;\n",
              "               padding: 0px;\">\n",
              "        <br><span style=\"font-weight:normal;\">Melissa Fonseca Veitia</span><br>\n",
              "         <br><span style=\"font-weight:normal;\">Darwin Yadir Londoño Ochoa</span><br>\n",
              "         <br><span style=\"font-weight:normal;\">Samir Romero Cárdenas</span><br>\n",
              "         <br><span style=\"font-weight:normal;\">Ruber Alberto Barrios Rodríguez</span><br>\n",
              "\n",
              "        <br>\n",
              "        <span style=\"font-weight:bold;\">Uniminuto</span><br>\n",
              "        <span style=\"font-weight:bold;\">Procesamiento de Lenguaje Natural</span><br>\n",
              "        <br>\n",
              "        <span style=\"font-weight:normal;\">Docente: Claudia Marcela Ospina Mosquera</span><br>\n",
              "        <br>\n",
              "        Febrero - 2024<br>\n",
              "        <br>\n",
              "    </h1>\n",
              "</div>\n",
              "\n",
              "\n",
              "<hr style=\"border: 1px solid rgba(195, 172, 71, 1);\"> <!-- Línea larga -->\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Actividad\n",
        "\n",
        " El estudiante, de manera colaborativa, elaborará un proyecto integrador sobre el uso de las redes neuronales recurrentes, en el cual tomará como base un código de predicción de textos, al finalizar, este debe predecir caracteres de un texto utilizando redes neuronales recurrentes y LSTM, con el objetivo de determinar las áreas de aplicación con base en las técnicas modernas de deep learning. Esta actividad le permitirá desarrollar resultados de aprendizaje de catalogar las redes recurrentes modernas y deducir las tendencias actuales de la IA."
      ],
      "metadata": {
        "id": "XqjMJaHUmKsr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import keras\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.callbacks import LambdaCallback\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LSTM\n",
        "import sys\n",
        "import random\n",
        "import io\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "WaFFi93uxJ87"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_mmK4iZeyWsj",
        "outputId": "6be74970-b7ad-4d88-8abf-723e262b43ca"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Cargamos un texto diferente al quijote almacenado en Drive\n",
        "with open(\"/content/drive/MyDrive/mitosyleyendas.txt\", \"r\") as f:\n",
        "    text = f.read().lower() #aplicamos minúsculas a todo el documento\n",
        "print(text)"
      ],
      "metadata": {
        "id": "VneWQSA5zcfq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3482f560-7e73-4500-9f8f-5367921d739e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dice la leyenda que en las calles de ocaña las gentes podían ver el fantasma del jinete negro, don antón garcía, caballero de la época colonial.\n",
            "\n",
            "el espectro iba vestido de negro, portaba un sombrero y unas alas anchas. de sus hombros caía una capa oscura y larga que le cubría todo el cuerpo. su aspecto causaba espanto y pavor a aquellos que se lo cruzaban.\n",
            "\n",
            "cuentan que, en vida, hizo construir un lago en una de sus fincas, cerca del río magdalena, para lo cual empleó mucha servidumbre. le encantaban los caballos, y todas las noches se podía oír su caballo negro saltar por las oscuras calles del lugar.\n",
            "\n",
            "cuando su esposa enfermó, don antón garcía le hizo una promesa a santa rita, patrona de los imposibles. sin embargo, esta promesa se le olvidó y, cuando don antón garcía falleció, san pedro le ordenó acudir cada noche a visitar el santuario de santa rita, hasta la consumación de los siglos.\n",
            " \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Longitud del texto: {}\".format(len(text)))\n",
        "print(text[0:500])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Fy-z3i6zj5y",
        "outputId": "ffd70673-9f05-443b-f508-1f7d5df4a95d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Longitud del texto: 904\n",
            "dice la leyenda que en las calles de ocaña las gentes podían ver el fantasma del jinete negro, don antón garcía, caballero de la época colonial.\n",
            "\n",
            "el espectro iba vestido de negro, portaba un sombrero y unas alas anchas. de sus hombros caía una capa oscura y larga que le cubría todo el cuerpo. su aspecto causaba espanto y pavor a aquellos que se lo cruzaban.\n",
            "\n",
            "cuentan que, en vida, hizo construir un lago en una de sus fincas, cerca del río magdalena, para lo cual empleó mucha servidumbre. le encan\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Procesamiento de Datos**"
      ],
      "metadata": {
        "id": "1TznN6LWrZoS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chars=sorted(list(set(text)))\n",
        "char_indices = dict((c,i) for i, c in enumerate(chars))\n",
        "indice_char = dict((i, c) for i, c in enumerate(chars))"
      ],
      "metadata": {
        "id": "NNeumyXXz39O"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chars[:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b10fA8kYS-7G",
        "outputId": "5b2194ca-1526-4f2d-89d7-a616125b56d9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['\\n',\n",
              " ' ',\n",
              " ',',\n",
              " '.',\n",
              " 'a',\n",
              " 'b',\n",
              " 'c',\n",
              " 'd',\n",
              " 'e',\n",
              " 'f',\n",
              " 'g',\n",
              " 'h',\n",
              " 'i',\n",
              " 'j',\n",
              " 'l',\n",
              " 'm',\n",
              " 'n',\n",
              " 'o',\n",
              " 'p',\n",
              " 'q',\n",
              " 'r',\n",
              " 's',\n",
              " 't',\n",
              " 'u',\n",
              " 'v',\n",
              " 'y',\n",
              " 'z',\n",
              " 'é',\n",
              " 'í',\n",
              " 'ñ',\n",
              " 'ó']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#indice_char\n",
        "print(\"Tiene\",len(chars),\"caracteres\") # se obtienen 31 caracteres\n",
        "char_indices"
      ],
      "metadata": {
        "id": "z3sjlVbZ0mcF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5742b06e-add3-4a56-ac99-90323a16fad9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tiene 31 caracteres\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'\\n': 0,\n",
              " ' ': 1,\n",
              " ',': 2,\n",
              " '.': 3,\n",
              " 'a': 4,\n",
              " 'b': 5,\n",
              " 'c': 6,\n",
              " 'd': 7,\n",
              " 'e': 8,\n",
              " 'f': 9,\n",
              " 'g': 10,\n",
              " 'h': 11,\n",
              " 'i': 12,\n",
              " 'j': 13,\n",
              " 'l': 14,\n",
              " 'm': 15,\n",
              " 'n': 16,\n",
              " 'o': 17,\n",
              " 'p': 18,\n",
              " 'q': 19,\n",
              " 'r': 20,\n",
              " 's': 21,\n",
              " 't': 22,\n",
              " 'u': 23,\n",
              " 'v': 24,\n",
              " 'y': 25,\n",
              " 'z': 26,\n",
              " 'é': 27,\n",
              " 'í': 28,\n",
              " 'ñ': 29,\n",
              " 'ó': 30}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Definia el tamaño de las secuencias. Puede dejar este valor por defecto.\n",
        "SEQ_LENGTH = 35\n",
        "step=3\n",
        "rawX = []\n",
        "rawy = []\n",
        "\n",
        "for i in range(0, len(text) - SEQ_LENGTH, step):#Ponemos text\n",
        "    rawX.append(text[i: i+SEQ_LENGTH])\n",
        "    rawy.append(text[i+SEQ_LENGTH])"
      ],
      "metadata": {
        "id": "7UGjnT2S5Z3B"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(rawX) #imprimimos lo que guardó cada vector\n",
        "print(rawy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ipIWB1PqtEEI",
        "outputId": "2b1d6fb0-c4a9-4aaa-f930-455dd6f84713"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['dice la leyenda que en las calles d', 'e la leyenda que en las calles de o', 'a leyenda que en las calles de ocañ', 'eyenda que en las calles de ocaña l', 'nda que en las calles de ocaña las ', ' que en las calles de ocaña las gen', 'e en las calles de ocaña las gentes', 'n las calles de ocaña las gentes po', 'as calles de ocaña las gentes podía', 'calles de ocaña las gentes podían v', 'les de ocaña las gentes podían ver ', ' de ocaña las gentes podían ver el ', ' ocaña las gentes podían ver el fan', 'aña las gentes podían ver el fantas', ' las gentes podían ver el fantasma ', 's gentes podían ver el fantasma del', 'entes podían ver el fantasma del ji', 'es podían ver el fantasma del jinet', 'podían ver el fantasma del jinete n', 'ían ver el fantasma del jinete negr', ' ver el fantasma del jinete negro, ', 'r el fantasma del jinete negro, don', 'l fantasma del jinete negro, don an', 'antasma del jinete negro, don antón', 'asma del jinete negro, don antón ga', 'a del jinete negro, don antón garcí', 'el jinete negro, don antón garcía, ', 'jinete negro, don antón garcía, cab', 'ete negro, don antón garcía, caball', ' negro, don antón garcía, caballero', 'gro, don antón garcía, caballero de', ', don antón garcía, caballero de la', 'on antón garcía, caballero de la ép', 'antón garcía, caballero de la época', 'ón garcía, caballero de la época co', 'garcía, caballero de la época colon', 'cía, caballero de la época colonial', ', caballero de la época colonial.\\n\\n', 'aballero de la época colonial.\\n\\nel ', 'llero de la época colonial.\\n\\nel esp', 'ro de la época colonial.\\n\\nel espect', 'de la época colonial.\\n\\nel espectro ', 'la época colonial.\\n\\nel espectro iba', 'época colonial.\\n\\nel espectro iba ve', 'ca colonial.\\n\\nel espectro iba vesti', 'colonial.\\n\\nel espectro iba vestido ', 'onial.\\n\\nel espectro iba vestido de ', 'al.\\n\\nel espectro iba vestido de neg', '\\n\\nel espectro iba vestido de negro,', 'l espectro iba vestido de negro, po', 'spectro iba vestido de negro, porta', 'ctro iba vestido de negro, portaba ', 'o iba vestido de negro, portaba un ', 'ba vestido de negro, portaba un som', 'vestido de negro, portaba un sombre', 'tido de negro, portaba un sombrero ', 'o de negro, portaba un sombrero y u', 'e negro, portaba un sombrero y unas', 'egro, portaba un sombrero y unas al', 'o, portaba un sombrero y unas alas ', 'portaba un sombrero y unas alas anc', 'taba un sombrero y unas alas anchas', 'a un sombrero y unas alas anchas. d', 'n sombrero y unas alas anchas. de s', 'ombrero y unas alas anchas. de sus ', 'rero y unas alas anchas. de sus hom', 'o y unas alas anchas. de sus hombro', ' unas alas anchas. de sus hombros c', 'as alas anchas. de sus hombros caía', 'alas anchas. de sus hombros caía un', 's anchas. de sus hombros caía una c', 'nchas. de sus hombros caía una capa', 'as. de sus hombros caía una capa os', ' de sus hombros caía una capa oscur', ' sus hombros caía una capa oscura y', 's hombros caía una capa oscura y la', 'ombros caía una capa oscura y larga', 'ros caía una capa oscura y larga qu', ' caía una capa oscura y larga que l', 'ía una capa oscura y larga que le c', 'una capa oscura y larga que le cubr', ' capa oscura y larga que le cubría ', 'pa oscura y larga que le cubría tod', 'oscura y larga que le cubría todo e', 'ura y larga que le cubría todo el c', ' y larga que le cubría todo el cuer', 'larga que le cubría todo el cuerpo.', 'ga que le cubría todo el cuerpo. su', 'que le cubría todo el cuerpo. su as', ' le cubría todo el cuerpo. su aspec', ' cubría todo el cuerpo. su aspecto ', 'bría todo el cuerpo. su aspecto cau', 'a todo el cuerpo. su aspecto causab', 'odo el cuerpo. su aspecto causaba e', ' el cuerpo. su aspecto causaba espa', ' cuerpo. su aspecto causaba espanto', 'erpo. su aspecto causaba espanto y ', 'o. su aspecto causaba espanto y pav', 'su aspecto causaba espanto y pavor ', 'aspecto causaba espanto y pavor a a', 'ecto causaba espanto y pavor a aque', 'o causaba espanto y pavor a aquello', 'ausaba espanto y pavor a aquellos q', 'aba espanto y pavor a aquellos que ', ' espanto y pavor a aquellos que se ', 'panto y pavor a aquellos que se lo ', 'to y pavor a aquellos que se lo cru', 'y pavor a aquellos que se lo cruzab', 'avor a aquellos que se lo cruzaban.', 'r a aquellos que se lo cruzaban.\\n\\nc', ' aquellos que se lo cruzaban.\\n\\ncuen', 'uellos que se lo cruzaban.\\n\\ncuentan', 'los que se lo cruzaban.\\n\\ncuentan qu', ' que se lo cruzaban.\\n\\ncuentan que, ', 'e se lo cruzaban.\\n\\ncuentan que, en ', 'e lo cruzaban.\\n\\ncuentan que, en vid', 'o cruzaban.\\n\\ncuentan que, en vida, ', 'ruzaban.\\n\\ncuentan que, en vida, hiz', 'aban.\\n\\ncuentan que, en vida, hizo c', 'n.\\n\\ncuentan que, en vida, hizo cons', '\\ncuentan que, en vida, hizo constru', 'entan que, en vida, hizo construir ', 'an que, en vida, hizo construir un ', 'que, en vida, hizo construir un lag', ', en vida, hizo construir un lago e', 'n vida, hizo construir un lago en u', 'ida, hizo construir un lago en una ', ', hizo construir un lago en una de ', 'izo construir un lago en una de sus', ' construir un lago en una de sus fi', 'nstruir un lago en una de sus finca', 'ruir un lago en una de sus fincas, ', 'r un lago en una de sus fincas, cer', 'n lago en una de sus fincas, cerca ', 'ago en una de sus fincas, cerca del', ' en una de sus fincas, cerca del rí', ' una de sus fincas, cerca del río m', 'a de sus fincas, cerca del río magd', 'e sus fincas, cerca del río magdale', 'us fincas, cerca del río magdalena,', 'fincas, cerca del río magdalena, pa', 'cas, cerca del río magdalena, para ', ', cerca del río magdalena, para lo ', 'erca del río magdalena, para lo cua', 'a del río magdalena, para lo cual e', 'el río magdalena, para lo cual empl', 'río magdalena, para lo cual empleó ', ' magdalena, para lo cual empleó muc', 'gdalena, para lo cual empleó mucha ', 'lena, para lo cual empleó mucha ser', 'a, para lo cual empleó mucha servid', 'para lo cual empleó mucha servidumb', 'a lo cual empleó mucha servidumbre.', 'o cual empleó mucha servidumbre. le', 'ual empleó mucha servidumbre. le en', ' empleó mucha servidumbre. le encan', 'pleó mucha servidumbre. le encantab', 'ó mucha servidumbre. le encantaban ', 'ucha servidumbre. le encantaban los', 'a servidumbre. le encantaban los ca', 'ervidumbre. le encantaban los cabal', 'idumbre. le encantaban los caballos', 'mbre. le encantaban los caballos, y', 'e. le encantaban los caballos, y to', 'le encantaban los caballos, y todas', 'encantaban los caballos, y todas la', 'antaban los caballos, y todas las n', 'aban los caballos, y todas las noch', 'n los caballos, y todas las noches ', 'os caballos, y todas las noches se ', 'caballos, y todas las noches se pod', 'allos, y todas las noches se podía ', 'os, y todas las noches se podía oír', ' y todas las noches se podía oír su', 'todas las noches se podía oír su ca', 'as las noches se podía oír su cabal', 'las noches se podía oír su caballo ', ' noches se podía oír su caballo neg', 'ches se podía oír su caballo negro ', 's se podía oír su caballo negro sal', 'e podía oír su caballo negro saltar', 'odía oír su caballo negro saltar po', 'a oír su caballo negro saltar por l', 'ír su caballo negro saltar por las ', 'su caballo negro saltar por las osc', 'caballo negro saltar por las oscura', 'allo negro saltar por las oscuras c', 'o negro saltar por las oscuras call', 'egro saltar por las oscuras calles ', 'o saltar por las oscuras calles del', 'altar por las oscuras calles del lu', 'ar por las oscuras calles del lugar', 'por las oscuras calles del lugar.\\n\\n', ' las oscuras calles del lugar.\\n\\ncua', 's oscuras calles del lugar.\\n\\ncuando', 'scuras calles del lugar.\\n\\ncuando su', 'ras calles del lugar.\\n\\ncuando su es', ' calles del lugar.\\n\\ncuando su espos', 'lles del lugar.\\n\\ncuando su esposa e', 's del lugar.\\n\\ncuando su esposa enfe', 'el lugar.\\n\\ncuando su esposa enfermó', 'lugar.\\n\\ncuando su esposa enfermó, d', 'ar.\\n\\ncuando su esposa enfermó, don ', '\\n\\ncuando su esposa enfermó, don ant', 'uando su esposa enfermó, don antón ', 'do su esposa enfermó, don antón gar', 'su esposa enfermó, don antón garcía', 'esposa enfermó, don antón garcía le', 'osa enfermó, don antón garcía le hi', ' enfermó, don antón garcía le hizo ', 'fermó, don antón garcía le hizo una', 'mó, don antón garcía le hizo una pr', ' don antón garcía le hizo una prome', 'n antón garcía le hizo una promesa ', 'ntón garcía le hizo una promesa a s', 'n garcía le hizo una promesa a sant', 'arcía le hizo una promesa a santa r', 'ía le hizo una promesa a santa rita', 'le hizo una promesa a santa rita, p', 'hizo una promesa a santa rita, patr', 'o una promesa a santa rita, patrona', 'na promesa a santa rita, patrona de', 'promesa a santa rita, patrona de lo', 'mesa a santa rita, patrona de los i', 'a a santa rita, patrona de los impo', ' santa rita, patrona de los imposib', 'nta rita, patrona de los imposibles', ' rita, patrona de los imposibles. s', 'ta, patrona de los imposibles. sin ', ' patrona de los imposibles. sin emb', 'trona de los imposibles. sin embarg', 'na de los imposibles. sin embargo, ', 'de los imposibles. sin embargo, est', 'los imposibles. sin embargo, esta p', ' imposibles. sin embargo, esta prom', 'posibles. sin embargo, esta promesa', 'ibles. sin embargo, esta promesa se', 'es. sin embargo, esta promesa se le', ' sin embargo, esta promesa se le ol', 'n embargo, esta promesa se le olvid', 'mbargo, esta promesa se le olvidó y', 'rgo, esta promesa se le olvidó y, c', ', esta promesa se le olvidó y, cuan', 'sta promesa se le olvidó y, cuando ', ' promesa se le olvidó y, cuando don', 'omesa se le olvidó y, cuando don an', 'sa se le olvidó y, cuando don antón', 'se le olvidó y, cuando don antón ga', 'le olvidó y, cuando don antón garcí', 'olvidó y, cuando don antón garcía f', 'idó y, cuando don antón garcía fall', ' y, cuando don antón garcía falleci', ' cuando don antón garcía falleció, ', 'ando don antón garcía falleció, san', 'o don antón garcía falleció, san pe', 'on antón garcía falleció, san pedro', 'antón garcía falleció, san pedro le', 'ón garcía falleció, san pedro le or', 'garcía falleció, san pedro le orden', 'cía falleció, san pedro le ordenó a', ' falleció, san pedro le ordenó acud', 'lleció, san pedro le ordenó acudir ', 'ció, san pedro le ordenó acudir cad', ', san pedro le ordenó acudir cada n', 'an pedro le ordenó acudir cada noch', 'pedro le ordenó acudir cada noche a', 'ro le ordenó acudir cada noche a vi', 'le ordenó acudir cada noche a visit', 'ordenó acudir cada noche a visitar ', 'enó acudir cada noche a visitar el ', ' acudir cada noche a visitar el san', 'udir cada noche a visitar el santua', 'r cada noche a visitar el santuario', 'ada noche a visitar el santuario de', ' noche a visitar el santuario de sa', 'che a visitar el santuario de santa', ' a visitar el santuario de santa ri', 'visitar el santuario de santa rita,', 'itar el santuario de santa rita, ha', 'r el santuario de santa rita, hasta', 'l santuario de santa rita, hasta la', 'antuario de santa rita, hasta la co', 'uario de santa rita, hasta la consu', 'io de santa rita, hasta la consumac', 'de santa rita, hasta la consumación', 'santa rita, hasta la consumación de', 'ta rita, hasta la consumación de lo', 'rita, hasta la consumación de los s', 'a, hasta la consumación de los sigl', 'hasta la consumación de los siglos.']\n",
            "['e', 'c', 'a', 'a', 'g', 't', ' ', 'd', 'n', 'e', 'e', 'f', 't', 'm', 'd', ' ', 'n', 'e', 'e', 'o', 'd', ' ', 't', ' ', 'r', 'a', 'c', 'a', 'e', ' ', ' ', ' ', 'o', ' ', 'l', 'i', '.', 'e', 'e', 'e', 'r', 'i', ' ', 's', 'd', 'd', 'n', 'r', ' ', 'r', 'b', 'u', 's', 'b', 'r', 'y', 'n', ' ', 'a', 'a', 'h', '.', 'e', 'u', 'h', 'b', 's', 'a', ' ', 'a', 'a', ' ', 'c', 'a', ' ', 'r', ' ', 'e', 'e', 'u', 'í', 't', 'o', 'l', 'u', 'p', ' ', ' ', 'p', 't', 'c', 's', 'a', 's', 'n', ' ', 'p', 'o', 'a', 'q', 'l', 's', 'u', 's', 'l', 'c', 'z', 'a', '\\n', 'u', 't', ' ', 'e', 'e', 'v', 'a', 'h', 'o', 'o', 't', 'i', 'u', 'l', 'o', 'n', 'n', 'd', 's', ' ', 'n', 's', 'c', 'c', 'd', ' ', 'o', 'a', 'a', 'n', ' ', 'r', 'l', 'c', 'l', 'm', 'e', 'm', 'h', 's', 'v', 'u', 'r', ' ', ' ', 'c', 't', 'a', 'l', ' ', 'b', 'l', ',', ' ', 'd', ' ', 's', 'o', 'e', 's', 'p', 'í', 'o', ' ', ' ', 'b', 'l', 'n', 'r', 's', 't', ' ', 'r', 'a', 'o', 'u', 's', 'a', 'e', 'd', ' ', 'g', '.', 'c', 'n', ' ', ' ', 'p', 'a', 'n', 'r', ',', 'o', 'a', 'ó', 'g', 'c', ' ', ' ', 'z', 'u', ' ', 'o', 's', 'a', 'a', 'a', 'i', ',', 'a', 'o', ' ', ' ', 's', 'm', 's', 'l', '.', 'i', 'e', 'a', 'o', 'e', 'a', 'r', 'e', ' ', ' ', ' ', 'v', 'ó', ',', 'u', 'd', 'd', ' ', 't', ' ', 'r', 'a', 'a', 'e', 'ó', 's', ' ', 'd', ' ', ' ', 'd', 'ó', 'c', 'i', 'c', 'a', 'o', 'e', ' ', 's', 'a', 'e', 's', 't', 'r', ' ', ' ', 'n', ' ', 't', ' ', 's', ' ', ' ', 'n', 'm', 'i', ' ', ' ', 's', 'i', 'o', '\\n']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_sentences=len(rawX)\n",
        "n_sentences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-KFFFNH206Sr",
        "outputId": "9743ec67-1e7d-427f-b034-6254e7eba873"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "290"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_SEQUENCES = 500\n",
        "\n",
        "perm = np.random.permutation(len(rawX)) #Permutar aleatoriamente una secuencia, o devolver un rango permutado.\n",
        "rawX, rawy = np.array(rawX), np.array(rawy)\n",
        "rawX, rawy = rawX[perm], rawy[perm]\n",
        "rawX, rawy = list(rawX[:MAX_SEQUENCES]), list(rawy[:MAX_SEQUENCES])\n",
        "\n",
        "print(len(rawX))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1XoOekpcxsBB",
        "outputId": "2348d8a3-5bec-4466-8719-cb4de81e5006"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "290\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.zeros((len(rawX), SEQ_LENGTH , len(chars)))\n",
        "y = np.zeros((len(rawX), len(chars)))"
      ],
      "metadata": {
        "id": "lIMjmQgUxpAl"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, sentence in enumerate(rawX):\n",
        "    for t, char in enumerate(sentence):\n",
        "        X[i, t, char_indices[char]] = 1\n",
        "    y[i, char_indices[rawy[i]]] = 1"
      ],
      "metadata": {
        "id": "RhtgCJEcxAEd"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X[:1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J9uVc_6QUfev",
        "outputId": "6d94ca64-540e-4dac-f3b8-4266a9767884"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 1., 0., ..., 0., 0., 0.]]])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y[:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bOCVudhWUjWT",
        "outputId": "c6ce465d-2029-4aa1-9f69-de4dae2d7532"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 1., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir el modelo\n",
        "model = Sequential()\n",
        "# Añadir una capa LSTM\n",
        "model.add(LSTM(128, input_shape=(SEQ_LENGTH, len(chars))))\n",
        "# Añadir una capa de dropout para evitar sobreajuste\n",
        "model.add(Dropout(0.5))\n",
        "# Añadir una capa densa con activación softmax para la salida\n",
        "model.add(Dense(len(chars), activation='softmax'))\n",
        "# Imprimir un resumen del modelo\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MPhU7j5S13ab",
        "outputId": "d0ed841b-1454-4f73-cd5d-f2073a6992ac"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm (LSTM)                 (None, 128)               81920     \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 128)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 31)                3999      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 85919 (335.62 KB)\n",
            "Trainable params: 85919 (335.62 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "ajALUVBWxXhN"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X,y,batch_size=128,epochs=250,verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TDZmq_HwU6ii",
        "outputId": "1604696b-0f63-4d98-f0ea-a8460401d597"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/250\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 2.7469 - accuracy: 0.2000\n",
            "Epoch 2/250\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 2.6720 - accuracy: 0.2379\n",
            "Epoch 3/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.6364 - accuracy: 0.2241\n",
            "Epoch 4/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 2.6967 - accuracy: 0.2207\n",
            "Epoch 5/250\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 2.6811 - accuracy: 0.2586\n",
            "Epoch 6/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.6704 - accuracy: 0.2276\n",
            "Epoch 7/250\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 2.6735 - accuracy: 0.2241\n",
            "Epoch 8/250\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 2.7256 - accuracy: 0.2172\n",
            "Epoch 9/250\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 2.6471 - accuracy: 0.2690\n",
            "Epoch 10/250\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 2.6440 - accuracy: 0.2310\n",
            "Epoch 11/250\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 2.6246 - accuracy: 0.2448\n",
            "Epoch 12/250\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 2.6185 - accuracy: 0.2655\n",
            "Epoch 13/250\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 2.5578 - accuracy: 0.2621\n",
            "Epoch 14/250\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 2.5696 - accuracy: 0.2448\n",
            "Epoch 15/250\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 2.6029 - accuracy: 0.2483\n",
            "Epoch 16/250\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 2.5293 - accuracy: 0.2552\n",
            "Epoch 17/250\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 2.5034 - accuracy: 0.2690\n",
            "Epoch 18/250\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 2.5263 - accuracy: 0.2655\n",
            "Epoch 19/250\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 2.5004 - accuracy: 0.2793\n",
            "Epoch 20/250\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 2.4552 - accuracy: 0.2655\n",
            "Epoch 21/250\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 2.4550 - accuracy: 0.2759\n",
            "Epoch 22/250\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 2.4179 - accuracy: 0.2724\n",
            "Epoch 23/250\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 2.4406 - accuracy: 0.2621\n",
            "Epoch 24/250\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 2.3734 - accuracy: 0.2793\n",
            "Epoch 25/250\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 2.3838 - accuracy: 0.3138\n",
            "Epoch 26/250\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 2.3952 - accuracy: 0.3069\n",
            "Epoch 27/250\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 2.3506 - accuracy: 0.2862\n",
            "Epoch 28/250\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 2.3484 - accuracy: 0.3207\n",
            "Epoch 29/250\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 2.3292 - accuracy: 0.2793\n",
            "Epoch 30/250\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 2.3698 - accuracy: 0.3172\n",
            "Epoch 31/250\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 2.2892 - accuracy: 0.3103\n",
            "Epoch 32/250\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 2.2499 - accuracy: 0.3517\n",
            "Epoch 33/250\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 2.2581 - accuracy: 0.3379\n",
            "Epoch 34/250\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 2.1879 - accuracy: 0.3552\n",
            "Epoch 35/250\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 2.2237 - accuracy: 0.3724\n",
            "Epoch 36/250\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 2.1868 - accuracy: 0.3345\n",
            "Epoch 37/250\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 2.1892 - accuracy: 0.3345\n",
            "Epoch 38/250\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 2.1865 - accuracy: 0.3172\n",
            "Epoch 39/250\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 2.1365 - accuracy: 0.3517\n",
            "Epoch 40/250\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 2.1471 - accuracy: 0.3310\n",
            "Epoch 41/250\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 2.0963 - accuracy: 0.3655\n",
            "Epoch 42/250\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 2.0805 - accuracy: 0.3759\n",
            "Epoch 43/250\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 2.1157 - accuracy: 0.3345\n",
            "Epoch 44/250\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 2.0563 - accuracy: 0.3621\n",
            "Epoch 45/250\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 2.0954 - accuracy: 0.3690\n",
            "Epoch 46/250\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 2.0390 - accuracy: 0.3621\n",
            "Epoch 47/250\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 2.0307 - accuracy: 0.3862\n",
            "Epoch 48/250\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 1.9510 - accuracy: 0.3897\n",
            "Epoch 49/250\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 1.9458 - accuracy: 0.3897\n",
            "Epoch 50/250\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 1.9262 - accuracy: 0.4241\n",
            "Epoch 51/250\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 1.9468 - accuracy: 0.4138\n",
            "Epoch 52/250\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 1.9244 - accuracy: 0.4552\n",
            "Epoch 53/250\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 1.8536 - accuracy: 0.4241\n",
            "Epoch 54/250\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 1.8588 - accuracy: 0.4207\n",
            "Epoch 55/250\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 1.8907 - accuracy: 0.4483\n",
            "Epoch 56/250\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 1.8940 - accuracy: 0.4069\n",
            "Epoch 57/250\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 1.8984 - accuracy: 0.4138\n",
            "Epoch 58/250\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 1.9906 - accuracy: 0.4069\n",
            "Epoch 59/250\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 1.7448 - accuracy: 0.4517\n",
            "Epoch 60/250\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 1.9087 - accuracy: 0.4586\n",
            "Epoch 61/250\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 1.8385 - accuracy: 0.4345\n",
            "Epoch 62/250\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 1.8379 - accuracy: 0.4241\n",
            "Epoch 63/250\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 1.7861 - accuracy: 0.4448\n",
            "Epoch 64/250\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 1.7140 - accuracy: 0.4621\n",
            "Epoch 65/250\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 1.6679 - accuracy: 0.4862\n",
            "Epoch 66/250\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 1.7462 - accuracy: 0.4621\n",
            "Epoch 67/250\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 1.6840 - accuracy: 0.4552\n",
            "Epoch 68/250\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 1.6122 - accuracy: 0.5207\n",
            "Epoch 69/250\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 1.7034 - accuracy: 0.4793\n",
            "Epoch 70/250\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 1.6342 - accuracy: 0.5000\n",
            "Epoch 71/250\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 1.5012 - accuracy: 0.5517\n",
            "Epoch 72/250\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 1.5622 - accuracy: 0.5000\n",
            "Epoch 73/250\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 1.5126 - accuracy: 0.5138\n",
            "Epoch 74/250\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 1.4546 - accuracy: 0.5448\n",
            "Epoch 75/250\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 1.4996 - accuracy: 0.4966\n",
            "Epoch 76/250\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 1.5583 - accuracy: 0.5069\n",
            "Epoch 77/250\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 1.5373 - accuracy: 0.5138\n",
            "Epoch 78/250\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 1.4553 - accuracy: 0.5276\n",
            "Epoch 79/250\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 1.4104 - accuracy: 0.5690\n",
            "Epoch 80/250\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 1.4612 - accuracy: 0.5310\n",
            "Epoch 81/250\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 1.4311 - accuracy: 0.5552\n",
            "Epoch 82/250\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 1.3449 - accuracy: 0.5483\n",
            "Epoch 83/250\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 1.3153 - accuracy: 0.5966\n",
            "Epoch 84/250\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 1.2495 - accuracy: 0.6138\n",
            "Epoch 85/250\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 1.2714 - accuracy: 0.6138\n",
            "Epoch 86/250\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 1.2985 - accuracy: 0.6207\n",
            "Epoch 87/250\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 1.2289 - accuracy: 0.6586\n",
            "Epoch 88/250\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 1.1895 - accuracy: 0.6069\n",
            "Epoch 89/250\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 1.3100 - accuracy: 0.5897\n",
            "Epoch 90/250\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 1.3631 - accuracy: 0.5793\n",
            "Epoch 91/250\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 1.2120 - accuracy: 0.6276\n",
            "Epoch 92/250\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 1.2466 - accuracy: 0.6241\n",
            "Epoch 93/250\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 1.2437 - accuracy: 0.6241\n",
            "Epoch 94/250\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 1.2051 - accuracy: 0.6448\n",
            "Epoch 95/250\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 1.1360 - accuracy: 0.6310\n",
            "Epoch 96/250\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 1.1832 - accuracy: 0.6241\n",
            "Epoch 97/250\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 1.1722 - accuracy: 0.6517\n",
            "Epoch 98/250\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 1.1370 - accuracy: 0.6379\n",
            "Epoch 99/250\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 1.1591 - accuracy: 0.6207\n",
            "Epoch 100/250\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 1.1040 - accuracy: 0.6759\n",
            "Epoch 101/250\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 1.0372 - accuracy: 0.6931\n",
            "Epoch 102/250\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 1.1333 - accuracy: 0.6724\n",
            "Epoch 103/250\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 1.0324 - accuracy: 0.6793\n",
            "Epoch 104/250\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 1.0862 - accuracy: 0.6414\n",
            "Epoch 105/250\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 1.0788 - accuracy: 0.6724\n",
            "Epoch 106/250\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.9802 - accuracy: 0.7103\n",
            "Epoch 107/250\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.9583 - accuracy: 0.6897\n",
            "Epoch 108/250\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 1.0161 - accuracy: 0.6931\n",
            "Epoch 109/250\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.9331 - accuracy: 0.6966\n",
            "Epoch 110/250\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 1.0157 - accuracy: 0.7000\n",
            "Epoch 111/250\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 1.0266 - accuracy: 0.6966\n",
            "Epoch 112/250\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.9490 - accuracy: 0.7276\n",
            "Epoch 113/250\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.9803 - accuracy: 0.7138\n",
            "Epoch 114/250\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.8811 - accuracy: 0.7621\n",
            "Epoch 115/250\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 0.9564 - accuracy: 0.6862\n",
            "Epoch 116/250\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.8515 - accuracy: 0.7552\n",
            "Epoch 117/250\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.8292 - accuracy: 0.7655\n",
            "Epoch 118/250\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.8427 - accuracy: 0.7552\n",
            "Epoch 119/250\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.8066 - accuracy: 0.7793\n",
            "Epoch 120/250\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.8019 - accuracy: 0.7655\n",
            "Epoch 121/250\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 0.7951 - accuracy: 0.7724\n",
            "Epoch 122/250\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.8020 - accuracy: 0.7759\n",
            "Epoch 123/250\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.7697 - accuracy: 0.7655\n",
            "Epoch 124/250\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.7945 - accuracy: 0.7552\n",
            "Epoch 125/250\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.7840 - accuracy: 0.7586\n",
            "Epoch 126/250\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.7271 - accuracy: 0.7897\n",
            "Epoch 127/250\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 0.7545 - accuracy: 0.7966\n",
            "Epoch 128/250\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.6452 - accuracy: 0.8483\n",
            "Epoch 129/250\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.6536 - accuracy: 0.8138\n",
            "Epoch 130/250\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.6648 - accuracy: 0.8172\n",
            "Epoch 131/250\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.7163 - accuracy: 0.7862\n",
            "Epoch 132/250\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.6466 - accuracy: 0.8172\n",
            "Epoch 133/250\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.6137 - accuracy: 0.8379\n",
            "Epoch 134/250\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.6060 - accuracy: 0.8414\n",
            "Epoch 135/250\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.5798 - accuracy: 0.8379\n",
            "Epoch 136/250\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.6142 - accuracy: 0.8069\n",
            "Epoch 137/250\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.7667 - accuracy: 0.7828\n",
            "Epoch 138/250\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.8318 - accuracy: 0.7517\n",
            "Epoch 139/250\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.6714 - accuracy: 0.8069\n",
            "Epoch 140/250\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.8042 - accuracy: 0.7586\n",
            "Epoch 141/250\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.7265 - accuracy: 0.7966\n",
            "Epoch 142/250\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.7242 - accuracy: 0.7931\n",
            "Epoch 143/250\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.6725 - accuracy: 0.8069\n",
            "Epoch 144/250\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.6319 - accuracy: 0.8138\n",
            "Epoch 145/250\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.6687 - accuracy: 0.7931\n",
            "Epoch 146/250\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.6327 - accuracy: 0.8069\n",
            "Epoch 147/250\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.6526 - accuracy: 0.7897\n",
            "Epoch 148/250\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.5531 - accuracy: 0.8586\n",
            "Epoch 149/250\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.6036 - accuracy: 0.8517\n",
            "Epoch 150/250\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.5888 - accuracy: 0.8172\n",
            "Epoch 151/250\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.5400 - accuracy: 0.8655\n",
            "Epoch 152/250\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.5630 - accuracy: 0.8552\n",
            "Epoch 153/250\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 0.5019 - accuracy: 0.8931\n",
            "Epoch 154/250\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 0.6171 - accuracy: 0.8345\n",
            "Epoch 155/250\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 0.5000 - accuracy: 0.8724\n",
            "Epoch 156/250\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.4953 - accuracy: 0.8862\n",
            "Epoch 157/250\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 0.5098 - accuracy: 0.8276\n",
            "Epoch 158/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.4531 - accuracy: 0.8724\n",
            "Epoch 159/250\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 0.4938 - accuracy: 0.8621\n",
            "Epoch 160/250\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 0.4505 - accuracy: 0.9034\n",
            "Epoch 161/250\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 0.4536 - accuracy: 0.8966\n",
            "Epoch 162/250\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.4342 - accuracy: 0.9000\n",
            "Epoch 163/250\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 0.3794 - accuracy: 0.9069\n",
            "Epoch 164/250\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.3905 - accuracy: 0.9069\n",
            "Epoch 165/250\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 0.3779 - accuracy: 0.9138\n",
            "Epoch 166/250\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 0.3923 - accuracy: 0.8931\n",
            "Epoch 167/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.3873 - accuracy: 0.9000\n",
            "Epoch 168/250\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 0.3760 - accuracy: 0.9207\n",
            "Epoch 169/250\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 0.3561 - accuracy: 0.9241\n",
            "Epoch 170/250\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.3082 - accuracy: 0.9483\n",
            "Epoch 171/250\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 0.3569 - accuracy: 0.9241\n",
            "Epoch 172/250\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 0.3112 - accuracy: 0.9276\n",
            "Epoch 173/250\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 0.2806 - accuracy: 0.9414\n",
            "Epoch 174/250\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 0.4725 - accuracy: 0.8655\n",
            "Epoch 175/250\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 0.4608 - accuracy: 0.8724\n",
            "Epoch 176/250\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 0.5016 - accuracy: 0.8690\n",
            "Epoch 177/250\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 0.5327 - accuracy: 0.8621\n",
            "Epoch 178/250\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 0.6453 - accuracy: 0.8034\n",
            "Epoch 179/250\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 0.6334 - accuracy: 0.8276\n",
            "Epoch 180/250\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 0.6157 - accuracy: 0.8069\n",
            "Epoch 181/250\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 0.5979 - accuracy: 0.8207\n",
            "Epoch 182/250\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.5417 - accuracy: 0.8379\n",
            "Epoch 183/250\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 0.6156 - accuracy: 0.8448\n",
            "Epoch 184/250\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 0.5141 - accuracy: 0.8655\n",
            "Epoch 185/250\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.5593 - accuracy: 0.8483\n",
            "Epoch 186/250\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 0.5374 - accuracy: 0.8414\n",
            "Epoch 187/250\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 0.4468 - accuracy: 0.8931\n",
            "Epoch 188/250\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 0.4754 - accuracy: 0.8655\n",
            "Epoch 189/250\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 0.4344 - accuracy: 0.8897\n",
            "Epoch 190/250\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 0.4508 - accuracy: 0.8690\n",
            "Epoch 191/250\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 0.4302 - accuracy: 0.8793\n",
            "Epoch 192/250\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 0.3539 - accuracy: 0.9000\n",
            "Epoch 193/250\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 0.3477 - accuracy: 0.9103\n",
            "Epoch 194/250\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 0.4299 - accuracy: 0.8828\n",
            "Epoch 195/250\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 0.3464 - accuracy: 0.9069\n",
            "Epoch 196/250\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.3992 - accuracy: 0.8966\n",
            "Epoch 197/250\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 0.3648 - accuracy: 0.8897\n",
            "Epoch 198/250\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 0.3121 - accuracy: 0.9310\n",
            "Epoch 199/250\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 0.2973 - accuracy: 0.9517\n",
            "Epoch 200/250\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 0.3056 - accuracy: 0.9103\n",
            "Epoch 201/250\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 0.2884 - accuracy: 0.9310\n",
            "Epoch 202/250\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 0.3122 - accuracy: 0.9310\n",
            "Epoch 203/250\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 0.2965 - accuracy: 0.9241\n",
            "Epoch 204/250\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 0.3668 - accuracy: 0.8862\n",
            "Epoch 205/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.4070 - accuracy: 0.8862\n",
            "Epoch 206/250\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 0.3991 - accuracy: 0.9000\n",
            "Epoch 207/250\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 0.2829 - accuracy: 0.9345\n",
            "Epoch 208/250\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 0.3018 - accuracy: 0.9310\n",
            "Epoch 209/250\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.3241 - accuracy: 0.9138\n",
            "Epoch 210/250\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.2807 - accuracy: 0.9310\n",
            "Epoch 211/250\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 0.2772 - accuracy: 0.9552\n",
            "Epoch 212/250\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 0.2780 - accuracy: 0.9310\n",
            "Epoch 213/250\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 0.2733 - accuracy: 0.9345\n",
            "Epoch 214/250\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.2583 - accuracy: 0.9379\n",
            "Epoch 215/250\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 0.2302 - accuracy: 0.9483\n",
            "Epoch 216/250\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 0.2241 - accuracy: 0.9414\n",
            "Epoch 217/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.2452 - accuracy: 0.9517\n",
            "Epoch 218/250\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 0.1985 - accuracy: 0.9655\n",
            "Epoch 219/250\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 0.2079 - accuracy: 0.9621\n",
            "Epoch 220/250\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 0.2001 - accuracy: 0.9690\n",
            "Epoch 221/250\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 0.2057 - accuracy: 0.9655\n",
            "Epoch 222/250\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 0.1878 - accuracy: 0.9621\n",
            "Epoch 223/250\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 0.1873 - accuracy: 0.9724\n",
            "Epoch 224/250\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 0.1727 - accuracy: 0.9690\n",
            "Epoch 225/250\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.1811 - accuracy: 0.9828\n",
            "Epoch 226/250\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 0.1821 - accuracy: 0.9655\n",
            "Epoch 227/250\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.1441 - accuracy: 0.9828\n",
            "Epoch 228/250\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.1515 - accuracy: 0.9655\n",
            "Epoch 229/250\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 0.1769 - accuracy: 0.9621\n",
            "Epoch 230/250\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.1696 - accuracy: 0.9759\n",
            "Epoch 231/250\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 0.1440 - accuracy: 0.9759\n",
            "Epoch 232/250\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 0.1583 - accuracy: 0.9793\n",
            "Epoch 233/250\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.1359 - accuracy: 0.9690\n",
            "Epoch 234/250\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 0.1472 - accuracy: 0.9793\n",
            "Epoch 235/250\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.1566 - accuracy: 0.9655\n",
            "Epoch 236/250\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 0.1775 - accuracy: 0.9552\n",
            "Epoch 237/250\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 0.1410 - accuracy: 0.9724\n",
            "Epoch 238/250\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.1841 - accuracy: 0.9655\n",
            "Epoch 239/250\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 0.1681 - accuracy: 0.9690\n",
            "Epoch 240/250\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 0.1504 - accuracy: 0.9724\n",
            "Epoch 241/250\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 0.1495 - accuracy: 0.9690\n",
            "Epoch 242/250\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 0.1318 - accuracy: 0.9759\n",
            "Epoch 243/250\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 0.1465 - accuracy: 0.9759\n",
            "Epoch 244/250\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 0.1215 - accuracy: 0.9862\n",
            "Epoch 245/250\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.1222 - accuracy: 0.9759\n",
            "Epoch 246/250\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.1272 - accuracy: 0.9862\n",
            "Epoch 247/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.1294 - accuracy: 0.9724\n",
            "Epoch 248/250\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.1349 - accuracy: 0.9621\n",
            "Epoch 249/250\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 0.1377 - accuracy: 0.9759\n",
            "Epoch 250/250\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 0.1615 - accuracy: 0.9621\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7fe20af10fd0>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sample(probs, temperature=1.0):\n",
        "    # Cast a float64 por motivos numéricos\n",
        "    probs = np.asarray(probs).astype('float64')\n",
        "\n",
        "    # logaritmo de probabilidades y aplicamos reducción\n",
        "    # por temperatura.\n",
        "    probs = np.log(probs) / temperature\n",
        "\n",
        "    # Volvemos a aplicar exponencial y normalizamos de nuevo\n",
        "    exp_probs = np.exp(probs)\n",
        "    probs = exp_probs / np.sum(exp_probs)\n",
        "\n",
        "    # Hacemos el sampling dadas las nuevas probabilidades\n",
        "    # de salida (ver doc. de np.random.multinomial)\n",
        "    samples = np.random.multinomial(1, probs, 1)\n",
        "    return np.argmax(samples)\n"
      ],
      "metadata": {
        "id": "A-NMMc8_xgUe"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import sys\n",
        "\n",
        "TEMPERATURES_TO_TRY = [0.2] #, 0.5, 1.0, 1.2]\n",
        "GENERATED_TEXT_LENGTH = 300\n",
        "\n",
        "def generate_text(seed_text, model, length=300, temperature=1, max_length=30):\n",
        "    \"\"\"Genera una secuencia de texto a partir de seed_text utilizando model.\n",
        "\n",
        "    La secuencia tiene longitud length y el sampling se hace con la temperature\n",
        "    definida.\n",
        "    \"\"\"\n",
        "\n",
        "    # Aquí guardaremos nuestro texto generado, que incluirá el\n",
        "    # texto origen\n",
        "    generated = seed_text\n",
        "\n",
        "    # Utilizar el modelo en un bucle de manera que generemos\n",
        "    # carácter a carácter. Habrá que construir los valores de\n",
        "    # X_pred de manera similar a como hemos hecho arriba, salvo que\n",
        "    # aquí sólo se necesita una oración\n",
        "    # Nótese que el x que utilicemos tiene que irse actualizando con\n",
        "    # los caracteres que se van generando. La secuencia de entrada al\n",
        "    # modelo tiene que ser una secuencia de tamaño SEQ_LENGTH que\n",
        "    # incluya el último caracter predicho.\n",
        "\n",
        "    prediction = []\n",
        "\n",
        "    for i in range(length):\n",
        "        # Make numpy array to hold seed\n",
        "        X = np.zeros((1, len(generated), len(chars) ))\n",
        "\n",
        "        # Set one-hot vectors for seed sequence\n",
        "        for t, char in enumerate(seed_text):\n",
        "            X[0, t, char_indices[char]] = 1\n",
        "\n",
        "        # Generate prediction for next character\n",
        "        preds = model.predict(X, verbose=0)[0]\n",
        "        # Choose a character from the prediction probabilities\n",
        "        next_index = sample(preds,0.2)\n",
        "        next_char = indice_char[next_index]\n",
        "\n",
        "        prediction.append(next_char)\n",
        "        # Add the predicted character to the seed sequence so the next prediction\n",
        "        # includes this character in it's seed.\n",
        "        #generated += next_char\n",
        "        seed_text = seed_text[1:] + next_char\n",
        "\n",
        "        print(next_char, end= \" \")\n",
        "        # Flush so we can see the prediction as it's generated\n",
        "        sys.stdout.flush()\n",
        "\n",
        "    prediction = ''.join(prediction)\n",
        "    sys.stdout.flush()\n",
        "\n",
        "    return generated\n",
        "\n",
        "\n",
        "def on_epoch_end(epoch, logs):\n",
        "  print(\"\\n\\n\\n\")\n",
        "\n",
        "  # Primero, seleccionamos una secuencia al azar para empezar a predecir\n",
        "  # a partir de ella\n",
        "  start_pos = random.randint(0, len(text) - SEQ_LENGTH - 1)\n",
        "  seed_text = text[start_pos:start_pos + SEQ_LENGTH]\n",
        "  for temperature in TEMPERATURES_TO_TRY:\n",
        "    print(\"------> Epoch: {} - Generando texto con temperature {}\".format(\n",
        "        epoch + 1, temperature))\n",
        "\n",
        "    generated_text = generate_text(seed_text, model,\n",
        "                                   GENERATED_TEXT_LENGTH, temperature)\n",
        "    print(\"Seed: {}\".format(seed_text))\n",
        "    print(\"Texto generado: {}\".format(generated_text))\n",
        "\n",
        "\n",
        "generation_callback = LambdaCallback(on_epoch_end=on_epoch_end)\n"
      ],
      "metadata": {
        "id": "yZ24djb3xoq5"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## TU CÓDIGO AQUÍ\n",
        "\n",
        "model.fit(X, y, batch_size=128, epochs=5, callbacks=generation_callback)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S1AAW8IXx8hx",
        "outputId": "1b9b7357-1e92-4684-b48a-2ccbd4d2b4db"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.1456 - accuracy: 0.9844\n",
            "\n",
            "\n",
            "\n",
            "------> Epoch: 1 - Generando texto con temperature 0.2\n",
            ", ,       s d d     p p s o o o o o r p s a r r v v v e v f a a o d d d t   t g   g o r u o l l l l m l m . e e e v c c c c c c e e c c c c c c e e d d       d d d   n t t a t a r r r r r r           b b b l l l m n m n m l m m           s s i i h h h . . r       e e e h u u o o o o o o l t n t n n n n     a a a a a a a a e e e     e e e u       o o o       s s o s o o o o u u u o i s c c c c c c c c c c e       d c o   d o t o t           n n n n r r t t         a a a a n n n n n n n t         a a a a a a a q q o o o o o o     o o s o o o l l l   u u u u u u u u u u u u l l l l l z n t t n t Seed: idumbre. le encantaban los caballos\n",
            "Texto generado: idumbre. le encantaban los caballos\n",
            "3/3 [==============================] - 19s 9s/step - loss: 0.1328 - accuracy: 0.9828\n",
            "Epoch 2/5\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.1298 - accuracy: 0.9844\n",
            "\n",
            "\n",
            "\n",
            "------> Epoch: 2 - Generando texto con temperature 0.2\n",
            "a a e e ó ó ó               s s o o a a   o o o o o o h s s t       s   n   a   a a a o o o   c u u u u u u l a l n n n n n   t   t t t o c a a a   a   a n n n n s s s t             s b b s n n s y , ,   o o o o o o a l l l l s   o o       s p p u u u r o s s         t n n c c c t t c i i c d d d       d     o o o o t n n n n n t t s i e   e e e e e e a a , ó ó ó u u d d       o o o o o   n n n n r t i i c c       c c i i c c a a o d o       o o o o n n n t     t s s r s t a a a a a a a ,       u o o o o s s       s s   s s n s s s s i i s i h h h , a a a e o o o \n",
            " d o o o a a a a     l   l l Seed: lvidó y, cuando don antón garcía fa\n",
            "Texto generado: lvidó y, cuando don antón garcía fa\n",
            "3/3 [==============================] - 19s 9s/step - loss: 0.1261 - accuracy: 0.9862\n",
            "Epoch 3/5\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.1644 - accuracy: 0.9688\n",
            "\n",
            "\n",
            "\n",
            "------> Epoch: 3 - Generando texto con temperature 0.2\n",
            "        s n n n n m m i i           s s s s i v e v v o o s u u s s d d d   s o l l   p p   t n n n n n t t t c c c c e e e e e e ó ó u ó ó   d d d d               s m r r r r c c i i c c a a a a a c c c a a a       o o o o o l e e e . e . . . . e e e u u u u u u e v v v u t e e u d d d d d d       n t   t t t   r b b b b b b s s s s s i y y y y y y y   , , p p b l l l l l o   e e e e e e e   t t l s v i i i i e e e u g g g g d d d d         n n t r r r r r r a a a a a a a a a e e e e e e e     , e e e e e e e e e i i i i i h h o o o o u r     d d o o     t t t           n n s s s s i i   s s Seed: r el santuario de santa rita, hasta\n",
            "Texto generado: r el santuario de santa rita, hasta\n",
            "3/3 [==============================] - 18s 9s/step - loss: 0.1378 - accuracy: 0.9828\n",
            "Epoch 4/5\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.1297 - accuracy: 0.9609\n",
            "\n",
            "\n",
            "\n",
            "------> Epoch: 4 - Generando texto con temperature 0.2\n",
            "e e e                   o o s   s   s s l s í i u i i i c s a a a e e     o n o o   d d d d t t t t t t r r     r e a a a a q m s s m i i i s i s i i . e e e e a   a v o o o o o o o o o o l l l l m     r c c c a a a a a   c e e e e   t e     e d d e e e ó ó ó ó r r i r i i i b b b b ó e e e e o o d o o   d a t t   t t t t     e m m m m l l l s     m m r s s s       a a a a a a a a a a a o u u u u u u e u   o e e l h h h í e h h h h h h h u u u u u u í c c c c c a a a a a a a a a a a a a a a   a       e e e e e l e l e e . . e e e m e h h h h h h h u o   o u u u t t t d d t t t t t     a r r a Seed: inete negro, don antón garcía, caba\n",
            "Texto generado: inete negro, don antón garcía, caba\n",
            "3/3 [==============================] - 20s 10s/step - loss: 0.1163 - accuracy: 0.9793\n",
            "Epoch 5/5\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.0786 - accuracy: 0.9844\n",
            "\n",
            "\n",
            "\n",
            "------> Epoch: 5 - Generando texto con temperature 0.2\n",
            "s v p p p f í í o o o           b b b l u u s s s n n t r r s c c c c c c c c a o o o     s     o o     o o a o l l s s l l l       p p e e e t t       d     d d n t t t t               n n n n n s s d s t s       t t s s s s s s s s s s n s d d d d   d         d d d d o d o o o     o r   l l l l b b f f f f c c c d c c c c c c c a c       d   d d   d d t t t t r     r r r r r r r         s b l l m n n n n m m i i i i y       e h u o o o o o o \n",
            " o s s t t   l l l l l m e e e e e v v f o t d d d d         d d d d       d c c c c c c a a i a a a a     c a a a a a         l l l l l e l e e . e . Seed: n los caballos, y todas las noches \n",
            "Texto generado: n los caballos, y todas las noches \n",
            "3/3 [==============================] - 20s 10s/step - loss: 0.1395 - accuracy: 0.9759\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7fe20af3f010>"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusiones\n",
        "Entrenamos un modelo LSTM con un accuracy del 98% aproximadamente, sin embargo, el texto que escogimos es muy corto y aún falta precisión en cada época, la predicción en la época 5 fue \"n los caballos, y todas las noches \" que tiene sentido gramatical."
      ],
      "metadata": {
        "id": "7ACf8kb1WJze"
      }
    }
  ]
}